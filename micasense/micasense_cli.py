import glob
import multiprocessing
import os
import warnings

import cv2
import pandas as pd
from mapboxgl.utils import df_to_geojson

import micasense.imageutils as imageutils
from micasense import batch
from micasense.capture import Capture
from micasense.imageset import ImageSet

warnings.filterwarnings('ignore')


def main():
    ##############################################################################################
    # NOTE: Only call main() for testing and quick runs. Otherwise run dp_all.py for production. #
    ##############################################################################################

    ###################
    # Parameter Setup #
    ###################

    # output settings

    # band aligned, reflectance corrected tifs
    save_stack = True
    # normalized RGB
    save_thumbnails = True
    # plots of various flight info
    save_diagnostics = True
    # overwrite existing output in project dir
    overwrite = True

    # image processing settings

    # panel serial of MicaSense calibrated reflectance panel
    panel_serial = 'RP04-1947298-OB'
    panel_albedo_defaults = [0.545, 0.544, 0.542, 0.536, 0.54]  # defaults for panel 'RP04-1947298-OB'
    # use downwelling light sensor data in the reflectance correction
    use_dls = True
    # do not process captures 3 std deviations lower than mean flight altitude.
    drop_low_altitude = True
    # do not process captures with shutter speed slower than 0.01. This is a magic number derived through testing.
    drop_slow_shutter_speed = True

    # directory settings

    # /altum directory auto-generated by dp_setup_directories.py
    altum_dir = r'D:\seed_area_metashape_auto_test\altum'
    # directory holding altum, and only altum .tifs. auto-generated by dp_setup_directories.py
    data_dir = os.path.join(altum_dir, '_flight_data')
    # full path with *.tif wildcard for glob. This is the Capture used to define warp_matrices.
    # Leave this as an empty string '' to align using rig relatives
    alignment_path = ''
    # full path with *.tif wildcard for glob. This is the Capture used for reflectance panel calibration.
    panel_path = r'D:\seed_area_metashape_auto_test\altum\_flight_data\0003SET\000\IMG_0000_*.tif'

    # dask settings
    use_dask = False
    client_address = 'tcp://192.168.1.4:8786'
    # -----------------------------

    # verify some output is True
    if not any((save_stack, save_diagnostics, save_thumbnails)):
        print('No output requested. Quitting.')

    # make directories for requested output
    print('Setting up required directories...')
    output_stack_dir = os.path.join(altum_dir, '_stacks')
    output_rgb_dir = os.path.join(altum_dir, '_rgb')
    output_diagnostic_dir = os.path.join(altum_dir, '_diagnostic_output')

    batch.make_dir_if_not_exist({output_diagnostic_dir: save_diagnostics,
                                 output_rgb_dir: save_thumbnails,
                                 output_stack_dir: save_stack})
    # -----------------------------

    ######################
    # Get Alignment Data #
    ######################

    if alignment_path:
        # Images to derive warp matrices. Alignment images perform best with man made features.
        alignment_images = glob.glob(alignment_path)
    else:
        # use rig relatives
        alignment_images = None
    match_index = 1  # Index of the band to align to
    max_alignment_iterations = 2500  # default value given in MicaSense github
    warp_mode = cv2.MOTION_HOMOGRAPHY  # MOTION_HOMOGRAPHY or MOTION_AFFINE.
    pyramid_levels = 1  # for images with RigRelatives, setting this to 0 or 1 may improve alignment

    print('Computing alignment information...')
    if alignment_images is not None:
        print('\tComputing Warp Matrices...')
        alignment_capture = Capture.from_file_list(alignment_images)

        # get warp_matrices
        warp_matrices, _ = imageutils.align_capture(alignment_capture, ref_index=match_index,
                                                    max_iterations=max_alignment_iterations,
                                                    warp_mode=warp_mode,
                                                    pyramid_levels=pyramid_levels)
    else:
        print('\tUsing Rig Relatives...')
        warp_matrices = None
    # ------------------------------

    ##################################################
    # Get reflectance panel Capture and panel albedo #
    ##################################################

    # Images to derive panel information.
    if panel_path:
        panel_images = glob.glob(panel_path)
    else:
        # process radiance only
        panel_images = None

    # make Capture object from the panel_images
    if panel_images is not None:
        print('Building panel Capture...')
        panel_capture = Capture.from_file_list(panel_images)

        print('Detected {} panels in panel Capture. This should be 5 for the MicaSense Altum.'
              .format(panel_capture.detect_panels()))
    else:
        panel_capture = None

    # get panel albedo
    if panel_capture is not None:
        # case where reflectance regions are auto detected or automatically found
        if panel_capture.panel_albedo() is not None and not any(v is None for v in panel_capture.panel_albedo()):
            panel_albedo = panel_capture.panel_albedo()
            print('\tFound panel {} albedo values: {}'.format(panel_serial, panel_albedo))
        # case where at least 1 band albedo value cannot be found. use hardcoded values from panel.
        else:
            panel_albedo = panel_albedo_defaults
            print('\tCould not find panel albedo values from panel serial number.')
            print('\tUsing panel {} hardcoded values: {}'.format(panel_serial, panel_albedo))

        if not panel_capture.panels_in_all_expected_images():
            print('{}'.format([i + 1 for i, p in enumerate(panel_capture.panels) if p.panel_corners() is None]))
            raise ValueError('Panel reflectance region not detected in the above bands.')

        irradiance_list = panel_capture.panel_irradiance(panel_albedo) + [0]
        print('\tImage type output is: reflectance')
    else:
        if use_dls:
            print('\tNo panel Capture entered. use_dls is True. Attempting to use DLS for reflectance values '
                  'calibration. No diagnostic images will be created.')
            irradiance_list = None
        else:
            print('\tNo panel Capture entered. use_dls value is False. Image output type will be: radiance. '
                  'No diagnostic images will be created.')
            irradiance_list = None
    # -----------------------------------------------

    # ----- Get all Captures -----
    print(f'Building ImageSet from {data_dir}')
    image_set = ImageSet.from_directory(data_dir, use_tqdm=True)

    # ----- Get all capture info as pandas DataFrame and visualize flight stats -----
    print('Building pandas DataFrame...')
    data, columns = image_set.as_nested_lists()
    df = pd.DataFrame.from_records(data, index='timestamp', columns=columns)

    # ----- Save geojson data for later -----
    print(f'Saving GEOJSON data to {altum_dir}...')
    geojson_data = df_to_geojson(df, columns[3:], lat='latitude', lon='longitude')
    with open(os.path.join(altum_dir, 'imageSet.json'), 'w') as f:
        f.write(str(geojson_data))

    # plot diagnostics
    if save_diagnostics:
        batch.write_panel_diagnostics(panel_capture=panel_capture,
                                      output_diagnostic_dir=output_diagnostic_dir,
                                      irradiance_list=irradiance_list)
        batch.write_flight_diagnostics(columns=columns, df=df, output_diagnostic_dir=output_diagnostic_dir)

    # if only diagnostics were requested, quit.
    if not any((save_stack, save_thumbnails)):
        quit()

    # drop high and low altitudes
    if drop_low_altitude:
        batch.drop_low_altitudes(df=df, image_set=image_set)

    if drop_slow_shutter_speed:
        batch.drop_slow_shutter_speeds(image_set)

    # free up dataframe memory
    del data, columns, df, geojson_data

    # ----- parallel process ImageSet -----
    if not use_dask:
        batch.parallel_process(function=batch.process_image_set,
                               iterable=image_set.captures,
                               parameters={'irradiance': irradiance_list,
                                           'warp_matrices': warp_matrices,
                                           'capture_len': len(image_set.captures[0].images),
                                           'output_stack_dir': output_stack_dir,
                                           'output_rgb_dir': output_rgb_dir,
                                           'save_stack': save_stack,
                                           'save_rgb': save_thumbnails,
                                           'overwrite': overwrite}
                               )
    elif use_dask and client_address:
        batch.load_balancer(
            iterable=image_set.captures,
            parameters={'irradiance': irradiance_list,
                        'warp_matrices': warp_matrices,
                        'capture_len': len(image_set.captures[0].images),
                        'output_stack_dir': output_stack_dir,
                        'output_rgb_dir': output_rgb_dir,
                        'save_stack': save_stack,
                        'save_rgb': save_thumbnails,
                        'overwrite': overwrite,
                        'client': client_address}
        )
    else:
        print('Fix use_dask flag or use_dask .yml value. Quitting ...')
        quit(1)

    # ----- Write metadata to log.csv and output images -----
    print('Writing log.csv and adding metadata to output stacks...')
    batch.write_metadata(image_set, os.path.split(altum_dir)[0], save_stack, save_thumbnails)


if __name__ == '__main__':
    multiprocessing.set_start_method('spawn')
    main()
